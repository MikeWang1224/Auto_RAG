import os
import re
import sys
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass
from typing import List, Dict

import firebase_admin
from firebase_admin import credentials, firestore

# ---------- å¸¸æ•¸ ----------
TOKENS_COLLECTION = os.getenv("FIREBASE_TOKENS_COLLECTION", "bull_tokens")
NEWS_COLLECTION_TSMC = "NEWS"
NEWS_COLLECTION_FOX = "NEWS_Foxxcon"
NEWS_COLLECTION_UMC = "NEWS_UMC"  # âœ… è¯é›»
SCORE_THRESHOLD = float(os.getenv("SCORE_THRESHOLD", "3.0"))
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "2"))
TAIWAN_TZ = timezone(timedelta(hours=8))


# ---------- è³‡æ–™çµæ§‹ ----------
@dataclass
class MatchResult:
    score: float
    reasons: List[str]


# ---------- Firebase åˆå§‹åŒ– ----------
def get_db():
    if not firebase_admin._apps:
        cred = credentials.ApplicationDefault()
        firebase_admin.initialize_app(cred)
    return firestore.client()


# ---------- è¼”åŠ©å‡½æ•¸ ----------
def parse_docid_time(docid: str):
    try:
        parts = docid.split("_")
        if len(parts) >= 2:
            return datetime.strptime(parts[-1], "%Y%m%d%H%M%S").replace(tzinfo=TAIWAN_TZ)
    except Exception:
        pass
    return None


# ---------- æ”¹è‰¯å¾Œæ–°èè¼‰å…¥ ----------
def load_news_items(db, col_name: str, days: int) -> List[Dict]:
    items, seen = [], set()
    now = datetime.now(TAIWAN_TZ)
    start = now - timedelta(days=days)

    print(f"[debug] ğŸ” æ­£åœ¨è®€å– Firestore é›†åˆï¼š{col_name}")
    for d in db.collection(col_name).stream():
        data = d.to_dict() or {}
        print(f"[debug] â†’ æ–‡ä»¶ {d.id} keys={list(data.keys())}")
        dt = parse_docid_time(d.id)
        if dt and dt < start:
            continue

        found = False
        for k, v in data.items():
            if k.startswith("news_") and isinstance(v, dict):
                title, content = str(v.get("title") or ""), str(v.get("content") or "")
                if title or content:
                    uniq = f"{title}|{content}"
                    if uniq not in seen:
                        seen.add(uniq)
                        items.append({"id": f"{d.id}#{k}", "title": title, "content": content, "ts": dt})
                        found = True

        # âœ… è‹¥æ²’æœ‰å·¢ç‹€æ ¼å¼ï¼Œç›´æ¥æª¢æŸ¥å¹³é¢æ¬„ä½
        if not found and ("title" in data or "content" in data):
            title, content = str(data.get("title") or ""), str(data.get("content") or "")
            uniq = f"{title}|{content}"
            if uniq not in seen and (title or content):
                seen.add(uniq)
                items.append({"id": d.id, "title": title, "content": content, "ts": dt})

    print(f"[debug] âœ… å…±è¼‰å…¥ {len(items)} ç¯‡æ–°è\n")
    items.sort(key=lambda x: x["ts"] or datetime.min.replace(tzinfo=TAIWAN_TZ), reverse=True)
    return items


# ---------- é—œéµå­—åˆ†æ ----------
def score_text(text: str, target: str) -> MatchResult:
    aliases = {
        "å°ç©é›»": ["å°ç©é›»", "tsmc", "2330"],
        "é´»æµ·": ["é´»æµ·", "hon hai", "2317", "foxconn", "å¯Œå£«åº·"],
        "è¯é›»": ["è¯é›»", "umc", "2303"],
    }

    text_norm = text.lower()
    alias_pattern = "|".join(map(re.escape, aliases.get(target, [target])))

    # è¯é›»ï¼šå…è¨±ç›¸é—œè©å‘½ä¸­
    related_umc_keywords = [
        "æ™¶åœ“ä»£å·¥", "æˆç†Ÿè£½ç¨‹", "8å‹", "8 å‹", "è»Šç”¨æ™¶ç‰‡", "é©…å‹•ic", "ä¸­éšè£½ç¨‹", "ä»£å·¥å» "
    ]

    if target == "è¯é›»":
        alias_or_related_pattern = alias_pattern + "|" + "|".join(map(re.escape, related_umc_keywords))
        if not re.search(alias_or_related_pattern, text_norm):
            return MatchResult(0.0, [])
    else:
        if not re.search(alias_pattern, text_norm):
            return MatchResult(0.0, [])

    # å‡è¨­ LLM åˆ†æåˆ†æ•¸é‚è¼¯ï¼ˆå¯¦éš›ä¸Šåœ¨åˆ¥å‡½æ•¸å‘¼å«ï¼‰
    score = 4.0  # æ¨¡æ“¬åˆ†æ•¸
    reasons = [f"å‘½ä¸­é—œéµè©ï¼Œèˆ‡ {target} ç›¸é—œ"]
    return MatchResult(score, reasons)


# ---------- åˆ†æä¸»é‚è¼¯ ----------
def analyze_target(db, collection_name: str, target: str, result_collection: str, force_direction=False):
    print(f"ğŸ” é–‹å§‹åˆ†æ {target} ({collection_name}) ...")
    items = load_news_items(db, collection_name, LOOKBACK_DAYS)
    if not items:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½• {target} çš„æ–°èã€‚")
        return

    hits = 0
    for item in items:
        text = f"{item['title']} {item['content']}"
        result = score_text(text, target)
        if result.score >= SCORE_THRESHOLD:
            hits += 1
            print(f"[HIT] {item['title']} ({result.score:.1f}) -> {result.reasons}")

    if hits == 0:
        print(f"ğŸ“­ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ {target} æ–°èã€‚")
    else:
        print(f"âœ… å…± {hits} ç¯‡èˆ‡ {target} ç›¸é—œçš„æ–°èã€‚")


# ---------- ä¸»ç¨‹å¼ ----------
def main():
    db = get_db()

    analyze_target(db, NEWS_COLLECTION_TSMC, "å°ç©é›»", "Groq_result")
    print("\n" + "=" * 70 + "\n")
    analyze_target(db, NEWS_COLLECTION_FOX, "é´»æµ·", "Groq_result_Foxxcon", force_direction=True)
    print("\n" + "=" * 70 + "\n")
    analyze_target(db, NEWS_COLLECTION_UMC, "è¯é›»", "Groq_result_UMC")  # âœ… è¯é›»


if __name__ == "__main__":
    main()

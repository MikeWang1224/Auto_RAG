# -*- coding: utf-8 -*-
"""
RAG å¼·åŒ–ç‰ˆï¼šæ–°è embedding + æŸ¥è©¢ LLM æ¨è«–ï¼ˆTSMC / HonHai / UMCï¼‰
ç‰ˆæœ¬ï¼šv1.0
"""

import os
import json
import time
import requests
from datetime import datetime

import firebase_admin
from firebase_admin import credentials, firestore

from sentence_transformers import SentenceTransformer, util

# -----------------------------
# Firebase åˆå§‹åŒ–
# -----------------------------
cred = credentials.Certificate("serviceAccountKey.json")
firebase_admin.initialize_app(cred)
db = firestore.client()

# -----------------------------
# Groq API
# -----------------------------
GROQ_KEY = "ä½ çš„GROQ_KEY"
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"

model_embed = SentenceTransformer("all-MiniLM-L6-v2")

# -----------------------------
# åƒæ•¸
# -----------------------------
COMPANY_KEYWORDS = {
    "TSMC": ["å°ç©é›»", "2330", "TSMC", "æ™¶åœ“ä»£å·¥"],
    "HonHai": ["é´»æµ·", "2317", "Foxconn"],
    "UMC": ["è¯é›»", "2303", "UMC"],
}

COLLECTION_NAME = "market_news"

# -----------------------------
# 1. æ–·å¥ & æ¸…æ´—
# -----------------------------
def clean_text(t):
    if not t:
        return ""
    t = t.replace("\n", " ").replace("\r", " ")
    t = t.replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    return t.strip()

# -----------------------------
# 2. å„²å­˜ embedding åˆ° Firebase
# -----------------------------
def save_news_with_embedding(date_str, company, news_list):
    doc = db.collection(COLLECTION_NAME).document(date_str)
    exists = doc.get().to_dict() or {}

    if company not in exists:
        exists[company] = []

    for news in news_list:
        text = clean_text(news["title"] + " " + news["content"])
        emb = model_embed.encode(text).tolist()

        exists[company].append({
            "title": news["title"],
            "content": news["content"],
            "embedding": emb,
            "timestamp": datetime.utcnow().isoformat(),
        })

    doc.set(exists)
    print(f"ğŸ”¥ å·²å¯«å…¥ Firebaseï¼š{company} å…± {len(news_list)} å‰‡")

# -----------------------------
# 3. å»é™¤é‡è¤‡æ–°è
# -----------------------------
def dedup_news(news_list):
    cleaned = []
    for item in news_list:
        duplicate = False
        for c in cleaned:
            sim = util.cos_sim(
                model_embed.encode(item["title"]),
                model_embed.encode(c["title"])
            ).item()
            if sim > 0.92:
                duplicate = True
                break
        if not duplicate:
            cleaned.append(item)
    return cleaned

# -----------------------------
# 4. RAG æŸ¥è©¢ï¼šæ‰¾æœ€ç›¸ä¼¼æ–°è
# -----------------------------
def rag_query(company, date_str):
    doc = db.collection(COLLECTION_NAME).document(date_str).get()
    data = doc.to_dict() or {}

    if company not in data:
        return "ç„¡æ–°è"

    news_items = data[company]

    # RAG å•å¥
    query = f"{company} ä»Šæ—¥è‚¡åƒ¹ç›¸é—œæ–°èç¸½çµ å¸‚å ´æƒ…ç·’ï¼Ÿæ¼²è·Œé¢¨éšªï¼Ÿä¸‰é»é‡é»ï¼Ÿ"

    q_emb = model_embed.encode(query)

    # æ‰¾ç›¸ä¼¼åº¦æœ€é«˜çš„å‰ N æ¢
    scored = []
    for n in news_items:
        score = util.cos_sim(q_emb, n["embedding"]).item()
        scored.append((score, n))

    scored.sort(reverse=True, key=lambda x: x[0])
    top_news = scored[:5]

    # æ•´ç† context
    context_blocks = []
    for score, item in top_news:
        context_blocks.append(f"[ç›¸é—œåº¦ {round(score,3)}] {item['title']}\n{item['content']}")

    context = "\n\n".join(context_blocks)

    # -----------------------------
    # Groq LLM å›ç­”
    # -----------------------------
    prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°è‚¡åˆ†æå¸«ã€‚

ä»¥ä¸‹æ˜¯èˆ‡ {company} ç›¸é—œåº¦æœ€é«˜çš„æ–°èæ‘˜è¦ï¼ˆRAG ç¯€éŒ„ï¼‰ï¼š

{context}

è«‹ç”¨ **æ¥µåº¦ç²¾æº–ã€ä¸å¯èƒ¡äº‚æ¨æ¸¬** çš„æ–¹å¼å›ç­”ï¼š

1. ä»Šæ—¥æ•´é«”æ–°èæƒ…ç·’ï¼ˆæ­£å‘ / ä¸­ç«‹ / è² å‘ï¼‰
2. æ˜æ—¥è‚¡åƒ¹ã€Œåæ¼² + / åè·Œ - / æŒå¹³ 0ã€
3. æœ€é—œéµçš„ä¸‰å‰‡ç†ç”±

è«‹ç”¨ä»¥ä¸‹ JSON å›è¦†ï¼š
{{
  "sentiment": "",
  "prediction": "",
  "reasons": []
}}
"""

    res = requests.post(
        GROQ_URL,
        headers={"Authorization": f"Bearer {GROQ_KEY}"},
        json={
            "model": "llama-3.1-70b-versatile",
            "messages": [
                {"role": "system", "content": "You are an expert financial analyst."},
                {"role": "user", "content": prompt},
            ]
        }
    ).json()

    msg = res["choices"][0]["message"]["content"]
    return msg

# -----------------------------
# 5. ä¸»æµç¨‹
# -----------------------------
def main():
    date_str = datetime.now().strftime("%Y-%m-%d")

    # å‡è¨­ä½ çš„æ–°èæŠ“å–çµæœå¦‚ä¸‹æ ¼å¼
    sample_news = {
        "TSMC": [
            {"title": "å°ç©é›»æ³•èªªå±•æœ›æ¨‚è§€", "content": "å…ˆé€²è£½ç¨‹éœ€æ±‚å¼·å‹ï¼Œä¾›æ‡‰éˆä¿¡å¿ƒæå‡ã€‚"},
            {"title": "å¤–è³‡çœ‹å¥½ AI éœ€æ±‚", "content": "å¸¶å‹•å°ç©é›»é•·æœŸç‡Ÿé‹æˆé•·ã€‚"},
        ],
        "HonHai": [
            {"title": "é´»æµ·é›»å‹•è»Šå°ˆæ¡ˆé€²åº¦æ›å…‰", "content": "æ–°å¹³å°é–‹ç™¼é †åˆ©ã€‚"},
        ],
        "UMC": [
            {"title": "è¯é›»æˆç†Ÿè£½ç¨‹ç”¢èƒ½æ”¹å–„", "content": "å‡ºè²¨é‡è¼ƒä¸Šå­£æˆé•·ã€‚"},
        ],
    }

    for company in sample_news:
        cleaned = dedup_news(sample_news[company])
        save_news_with_embedding(date_str, company, cleaned)

    # 3å®¶å…¬å¸ RAG æŸ¥è©¢
    for company in ["TSMC", "HonHai", "UMC"]:
        result = rag_query(company, date_str)
        print("==============")
        print(f"ğŸ“Œ {company} RAG æ¨è«–\n{result}")

if __name__ == "__main__":
    main()
